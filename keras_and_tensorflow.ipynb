{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with keras and tensorflow\n",
    "\n",
    "N.B. You will need to pip install keras and tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson we'll use sklearn's built-in breast cancer dataset. The next cell loads the data and prints the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting our data and initializing a Scaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming our data\n",
    "X_train_s = ss.transform(X_train)\n",
    "X_test_s = ss.transform(X_test)\n",
    "\n",
    "X_train_s.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model and layer types\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing and compiling our model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "inputs = X_train_s.shape[1]\n",
    "\n",
    "hiddens = inputs\n",
    "\n",
    "model.add(Dense(hiddens, input_dim= inputs, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "adam = Adam()\n",
    "\n",
    "model.compile(adam, loss='mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/110\n",
      "426/426 [==============================] - 0s 449us/step - loss: 1.3991 - val_loss: 0.9374\n",
      "Epoch 2/110\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.6573 - val_loss: 0.5287\n",
      "Epoch 3/110\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.4139 - val_loss: 0.3613\n",
      "Epoch 4/110\n",
      "426/426 [==============================] - 0s 61us/step - loss: 0.3059 - val_loss: 0.2722\n",
      "Epoch 5/110\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.2378 - val_loss: 0.2210\n",
      "Epoch 6/110\n",
      "426/426 [==============================] - 0s 55us/step - loss: 0.1960 - val_loss: 0.1811\n",
      "Epoch 7/110\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.1669 - val_loss: 0.1533\n",
      "Epoch 8/110\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.1465 - val_loss: 0.1448\n",
      "Epoch 9/110\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.1292 - val_loss: 0.1277\n",
      "Epoch 10/110\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.1163 - val_loss: 0.1159\n",
      "Epoch 11/110\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.1070 - val_loss: 0.1085\n",
      "Epoch 12/110\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.0990 - val_loss: 0.1048\n",
      "Epoch 13/110\n",
      "426/426 [==============================] - 0s 74us/step - loss: 0.0923 - val_loss: 0.0988\n",
      "Epoch 14/110\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0872 - val_loss: 0.0972\n",
      "Epoch 15/110\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.0819 - val_loss: 0.0925\n",
      "Epoch 16/110\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0784 - val_loss: 0.0917\n",
      "Epoch 17/110\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.0755 - val_loss: 0.0895\n",
      "Epoch 18/110\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0721 - val_loss: 0.0872\n",
      "Epoch 19/110\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0694 - val_loss: 0.0863\n",
      "Epoch 20/110\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0666 - val_loss: 0.0841\n",
      "Epoch 21/110\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0644 - val_loss: 0.0825\n",
      "Epoch 22/110\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0625 - val_loss: 0.0827\n",
      "Epoch 23/110\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0610 - val_loss: 0.0801\n",
      "Epoch 24/110\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0585 - val_loss: 0.0797\n",
      "Epoch 25/110\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0568 - val_loss: 0.0792\n",
      "Epoch 26/110\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0552 - val_loss: 0.0787\n",
      "Epoch 27/110\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0534 - val_loss: 0.0774\n",
      "Epoch 28/110\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0524 - val_loss: 0.0771\n",
      "Epoch 29/110\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.0511 - val_loss: 0.0771\n",
      "Epoch 30/110\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0499 - val_loss: 0.0766\n",
      "Epoch 31/110\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.0492 - val_loss: 0.0772\n",
      "Epoch 32/110\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0480 - val_loss: 0.0754\n",
      "Epoch 33/110\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0469 - val_loss: 0.0749\n",
      "Epoch 34/110\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.0464 - val_loss: 0.0748\n",
      "Epoch 35/110\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0458 - val_loss: 0.0729\n",
      "Epoch 36/110\n",
      "426/426 [==============================] - 0s 77us/step - loss: 0.0446 - val_loss: 0.0736\n",
      "Epoch 37/110\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0444 - val_loss: 0.0724\n",
      "Epoch 38/110\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0438 - val_loss: 0.0732\n",
      "Epoch 39/110\n",
      "426/426 [==============================] - 0s 60us/step - loss: 0.0432 - val_loss: 0.0708\n",
      "Epoch 40/110\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0426 - val_loss: 0.0695\n",
      "Epoch 41/110\n",
      "426/426 [==============================] - 0s 63us/step - loss: 0.0416 - val_loss: 0.0711\n",
      "Epoch 42/110\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0413 - val_loss: 0.0692\n",
      "Epoch 43/110\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0405 - val_loss: 0.0702\n",
      "Epoch 44/110\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0403 - val_loss: 0.0676\n",
      "Epoch 45/110\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0407 - val_loss: 0.0702\n",
      "Epoch 46/110\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.0392 - val_loss: 0.0661\n",
      "Epoch 47/110\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0389 - val_loss: 0.0658\n",
      "Epoch 48/110\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.0378 - val_loss: 0.0673\n",
      "Epoch 49/110\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.0377 - val_loss: 0.0646\n",
      "Epoch 50/110\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.0370 - val_loss: 0.0663\n",
      "Epoch 51/110\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0365 - val_loss: 0.0652\n",
      "Epoch 52/110\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0363 - val_loss: 0.0666\n",
      "Epoch 53/110\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0355 - val_loss: 0.0643\n",
      "Epoch 54/110\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0352 - val_loss: 0.0641\n",
      "Epoch 55/110\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.0348 - val_loss: 0.0630\n",
      "Epoch 56/110\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0343 - val_loss: 0.0648\n",
      "Epoch 57/110\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0343 - val_loss: 0.0643\n",
      "Epoch 58/110\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0338 - val_loss: 0.0654\n",
      "Epoch 59/110\n",
      "426/426 [==============================] - 0s 45us/step - loss: 0.0331 - val_loss: 0.0634\n",
      "Epoch 60/110\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0330 - val_loss: 0.0632\n",
      "Epoch 61/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0324 - val_loss: 0.0629\n",
      "Epoch 62/110\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0318 - val_loss: 0.0626\n",
      "Epoch 63/110\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0317 - val_loss: 0.0625\n",
      "Epoch 64/110\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0314 - val_loss: 0.0617\n",
      "Epoch 65/110\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0308 - val_loss: 0.0642\n",
      "Epoch 66/110\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0309 - val_loss: 0.0622\n",
      "Epoch 67/110\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0302 - val_loss: 0.0644\n",
      "Epoch 68/110\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0303 - val_loss: 0.0615\n",
      "Epoch 69/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0300 - val_loss: 0.0615\n",
      "Epoch 70/110\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0296 - val_loss: 0.0624\n",
      "Epoch 71/110\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0293 - val_loss: 0.0608\n",
      "Epoch 72/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0290 - val_loss: 0.0617\n",
      "Epoch 73/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0285 - val_loss: 0.0600\n",
      "Epoch 74/110\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0281 - val_loss: 0.0605\n",
      "Epoch 75/110\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0281 - val_loss: 0.0604\n",
      "Epoch 76/110\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0278 - val_loss: 0.0620\n",
      "Epoch 77/110\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0274 - val_loss: 0.0611\n",
      "Epoch 78/110\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0277 - val_loss: 0.0616\n",
      "Epoch 79/110\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0268 - val_loss: 0.0600\n",
      "Epoch 80/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 30us/step - loss: 0.0264 - val_loss: 0.0590\n",
      "Epoch 81/110\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0265 - val_loss: 0.0594\n",
      "Epoch 82/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0261 - val_loss: 0.0603\n",
      "Epoch 83/110\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0259 - val_loss: 0.0599\n",
      "Epoch 84/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0256 - val_loss: 0.0592\n",
      "Epoch 85/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0254 - val_loss: 0.0593\n",
      "Epoch 86/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0253 - val_loss: 0.0580\n",
      "Epoch 87/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0249 - val_loss: 0.0579\n",
      "Epoch 88/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0250 - val_loss: 0.0589\n",
      "Epoch 89/110\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0245 - val_loss: 0.0571\n",
      "Epoch 90/110\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0247 - val_loss: 0.0585\n",
      "Epoch 91/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0241 - val_loss: 0.0576\n",
      "Epoch 92/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0237 - val_loss: 0.0575\n",
      "Epoch 93/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0236 - val_loss: 0.0572\n",
      "Epoch 94/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0237 - val_loss: 0.0591\n",
      "Epoch 95/110\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0234 - val_loss: 0.0564\n",
      "Epoch 96/110\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0230 - val_loss: 0.0570\n",
      "Epoch 97/110\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0229 - val_loss: 0.0573\n",
      "Epoch 98/110\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0225 - val_loss: 0.0565\n",
      "Epoch 99/110\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0227 - val_loss: 0.0559\n",
      "Epoch 100/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0224 - val_loss: 0.0561\n",
      "Epoch 101/110\n",
      "426/426 [==============================] - 0s 36us/step - loss: 0.0222 - val_loss: 0.0576\n",
      "Epoch 102/110\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0222 - val_loss: 0.0549\n",
      "Epoch 103/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0217 - val_loss: 0.0572\n",
      "Epoch 104/110\n",
      "426/426 [==============================] - 0s 36us/step - loss: 0.0214 - val_loss: 0.0550\n",
      "Epoch 105/110\n",
      "426/426 [==============================] - 0s 36us/step - loss: 0.0213 - val_loss: 0.0544\n",
      "Epoch 106/110\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0209 - val_loss: 0.0560\n",
      "Epoch 107/110\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0209 - val_loss: 0.0561\n",
      "Epoch 108/110\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0207 - val_loss: 0.0541\n",
      "Epoch 109/110\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0204 - val_loss: 0.0539\n",
      "Epoch 110/110\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0206 - val_loss: 0.0542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a35c482b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting our model\n",
    "model.fit(X_train_s, y_train,\n",
    "          validation_data = (X_test_s, y_test), epochs=110)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0204 - val_loss: 0.0544\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0201 - val_loss: 0.0546\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0201 - val_loss: 0.0539\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0207 - val_loss: 0.0525\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.0199 - val_loss: 0.0567\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0203 - val_loss: 0.0528\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0198 - val_loss: 0.0538\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0191 - val_loss: 0.0534\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.0193 - val_loss: 0.0519\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0186 - val_loss: 0.0522\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0188 - val_loss: 0.0537\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0185 - val_loss: 0.0521\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0184 - val_loss: 0.0532\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.0184 - val_loss: 0.0517\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0186 - val_loss: 0.0516\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 45us/step - loss: 0.0182 - val_loss: 0.0533\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 45us/step - loss: 0.0178 - val_loss: 0.0507\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.0179 - val_loss: 0.0518\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0175 - val_loss: 0.0512\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0176 - val_loss: 0.0509\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.0171 - val_loss: 0.0522\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.0176 - val_loss: 0.0501\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0178 - val_loss: 0.0522\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0171 - val_loss: 0.0519\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0169 - val_loss: 0.0499\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0165 - val_loss: 0.0513\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0166 - val_loss: 0.0517\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.0163 - val_loss: 0.0507\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0166 - val_loss: 0.0498\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 62us/step - loss: 0.0159 - val_loss: 0.0484\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0162 - val_loss: 0.0500\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 59us/step - loss: 0.0157 - val_loss: 0.0512\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 67us/step - loss: 0.0155 - val_loss: 0.0484\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0157 - val_loss: 0.0493\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0154 - val_loss: 0.0501\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0149 - val_loss: 0.0488\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0155 - val_loss: 0.0494\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0150 - val_loss: 0.0516\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0149 - val_loss: 0.0488\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0145 - val_loss: 0.0502\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.0148 - val_loss: 0.0506\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 42us/step - loss: 0.0151 - val_loss: 0.0479\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0145 - val_loss: 0.0490\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0143 - val_loss: 0.0482\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.0138 - val_loss: 0.0491\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0145 - val_loss: 0.0483\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0142 - val_loss: 0.0501\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 45us/step - loss: 0.0140 - val_loss: 0.0502\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.0135 - val_loss: 0.0511\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0136 - val_loss: 0.0480\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0131 - val_loss: 0.0488\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0132 - val_loss: 0.0479\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 54us/step - loss: 0.0132 - val_loss: 0.0499\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0133 - val_loss: 0.0507\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0131 - val_loss: 0.0497\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0130 - val_loss: 0.0478\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0509\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0126 - val_loss: 0.0483\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0497\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 61us/step - loss: 0.0128 - val_loss: 0.0481\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0490\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0127 - val_loss: 0.0512\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0129 - val_loss: 0.0534\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0126 - val_loss: 0.0483\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0123 - val_loss: 0.0482\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0122 - val_loss: 0.0512\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0121 - val_loss: 0.0487\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0118 - val_loss: 0.0487\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0122 - val_loss: 0.0492\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0121 - val_loss: 0.0491\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 36us/step - loss: 0.0118 - val_loss: 0.0494\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0119 - val_loss: 0.0495\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0115 - val_loss: 0.0507\n",
      "Epoch 74/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0114 - val_loss: 0.0483\n",
      "Epoch 75/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0530\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 36us/step - loss: 0.0125 - val_loss: 0.0557\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0120 - val_loss: 0.0496\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0115 - val_loss: 0.0501\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0110 - val_loss: 0.0530\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 35us/step - loss: 0.0110 - val_loss: 0.0496\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0111 - val_loss: 0.0513\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0509\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0531\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0113 - val_loss: 0.0504\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0121 - val_loss: 0.0524\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 36us/step - loss: 0.0110 - val_loss: 0.0517\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0111 - val_loss: 0.0508\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.0105 - val_loss: 0.0511\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 36us/step - loss: 0.0103 - val_loss: 0.0533\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0102 - val_loss: 0.0516\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0104 - val_loss: 0.0506\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0103 - val_loss: 0.0518\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 36us/step - loss: 0.0102 - val_loss: 0.0522\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0537\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 41us/step - loss: 0.0100 - val_loss: 0.0522\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0099 - val_loss: 0.0525\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0099 - val_loss: 0.0522\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.0100 - val_loss: 0.0512\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0099 - val_loss: 0.0527\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0536\n"
     ]
    }
   ],
   "source": [
    "# Storing that fit as a history log\n",
    "\n",
    "history_log = model.fit(X_train_s, y_train,\n",
    "          validation_data = (X_test_s, y_test), epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a35ff1e80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting our losses\n",
    "\n",
    "train_loss = history_log.history['loss']\n",
    "test_loss = history_log.history['val_loss']\n",
    "\n",
    "\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(test_loss, label='Testing Loss')\n",
    "\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow as a graph constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing the graph\n",
    "\n",
    "a = 3\n",
    "b = 5\n",
    "c = a+ b\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a += 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(3)\n",
    "b = tf.Variable(5)\n",
    "c = a + b\n",
    "d = a + c * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = sess.run(d)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting a session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_train_s.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-66-d26d6f2c7d0c>:6: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Applications/anaconda3/envs/learn-env/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:514: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 30))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "\n",
    "hid = tf.layers.dense(X, 30, activation=tf.nn.relu)\n",
    "y_hat = tf.layers.dense(hid, 1, activation=tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.losses.log_loss(y, y_hat)\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "training_run = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3776223776223776"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for _ in range(100):\n",
    "        sess.run(training_run, feed_dict={X: X_train_s, y: y_train.reshape(-1, 1)})\n",
    "        \n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})\n",
    "\n",
    "classes = (pred > 0.5).astype(int)\n",
    "\n",
    "metrics.accuracy_score(y_test.reshape(-1, 1), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
